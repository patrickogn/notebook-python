{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HTML Refresher\n",
    "This part is based on chapter 11 of *Automate the Boring Stuff with Python* by Al Sweigart\n",
    "\n",
    "HTML files are plain text files containing *tags*, which are words enclosed in angle brackets. Tags tell the browser how to format the web page. A starting tag and closing tag can enclose some text to form an element. The text (or inner HTML) is the content between the starting and closing tags.\n",
    "\n",
    "There are many different tags in HTML. Some of these tags have extra properties in the form of attributes within the angle brackets. For example, the `<a>` tag encloses text that should be a link.\n",
    "\n",
    "Some elements have an `id` attribute that is used to uniquely identify the element in the page. You will often instruct your programs to seek out an element by its id attribute, so figuring out an element’s id attribute using the browser’s developer tools is a common task in writing web scraping programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << EOF > data/example.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Hello!</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Hello World!</h1>\n",
    "You are extremely welcome!<br>\n",
    "<br>\n",
    "The <a href=\\\"https://github.com/datsoftlyngby/dat4sem2019spring-python-materials\\\">Lecture Notes</a>.<br>\n",
    "<div>\n",
    "<p>paragraph 1</p>\n",
    "<p>and paragraph 2: <span id=\"span01\">This is span 1</span id=\"span02\"><span id=\"span03\">Second span element</span>\n",
    "<span class=\"red_border\">Here is the third span</span>\n",
    "</p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\r\n",
      "<html>\r\n",
      "<head>\r\n",
      "<title>Hello!</title>\r\n",
      "</head>\r\n",
      "<body>\r\n",
      "<h1>Hello World!</h1>\r\n",
      "You are extremely welcome!<br>\r\n",
      "<br>\r\n",
      "The <a href=\\\"https://github.com/datsoftlyngby/dat4sem2019spring-python-materials\\\">Lecture Notes</a>.<br>\r\n",
      "<div>\r\n",
      "<p>paragraph 1</p>\r\n",
      "<p>and paragraph 2: <span id=\"span01\">This is span 1</span id=\"span02\"><span id=\"span03\">Second span element</span>\r\n",
      "<span class=\"red_border\">Here is the third span</span>\r\n",
      "</p>\r\n",
      "</div>\r\n",
      "</body>\r\n",
      "</html>\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# View a Page's HTML Sources\n",
    "\n",
    "Here, I will only describe how to use Firefox' development features.\n",
    "\n",
    "To view a page's sources right click on it and choose **View page source** which opens a new tab with the HTML sources.\n",
    "\n",
    "<img src=\"images/view_source_small.png\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Firefox, you can bring up the Web Developer Tools Inspector by pressing `CTRL-SHIFT-C` on Windows and Linux or by `CMD-OPTION-C` on OS X.\n",
    "\n",
    "<img src=\"images/inspector_small.png\" width=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parsing HTML with BeautifulSoup\n",
    "\n",
    "BeautifulSoup is a module for parsing and extracting information from HTML sources. The module’s name is bs4. In case it is not already installed on your machine:\n",
    "- install it with `pip install beautifulsoup4`. While beautifulsoup4 is the name used for installation, \n",
    "- to import BeautifulSoup you have to use `import bs4`.\n",
    "\n",
    "According to its documentation (https://www.crummy.com/software/BeautifulSoup/) *\"Beautiful Soup parses anything you give it, and does the tree traversal stuff for you. You can tell it \"Find all the links\", or \"Find all the links of class externalLink\", or \"Find all the links whose urls match \"foo.com\", or \"Find the table heading that's got bold text, then give me that text.\"\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating a BeautifulSoup Object from a Local HTML File\n",
    "\n",
    "- The `bs4.BeautifulSoup()` function needs to be called with a string containing the HTML it will parse. \n",
    "- The `bs4.BeautifulSoup()` function returns is a `BeautifulSoup` object.\n",
    "\n",
    "You can load a local HTML file and pass a file object to `bs4.BeautifulSoup()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Hello!\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Hello World!\n",
      "  </h1>\n",
      "  You are extremely welcome!\n",
      "  <br/>\n",
      "  <br/>\n",
      "  The\n",
      "  <a href='\\\"https://github.com/datsoftlyngby/dat4sem2019spring-python-materials\\\"'>\n",
      "   Lecture Notes\n",
      "  </a>\n",
      "  .\n",
      "  <br/>\n",
      "  <div>\n",
      "   <p>\n",
      "    paragraph 1\n",
      "   </p>\n",
      "   <p>\n",
      "    and paragraph 2:\n",
      "    <span id=\"span01\">\n",
      "     This is span 1\n",
      "    </span>\n",
      "    <span id=\"span03\">\n",
      "     Second span element\n",
      "    </span>\n",
      "    <span class=\"red_border\">\n",
      "     Here is the third span\n",
      "    </span>\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "with open('./data/example.html') as f:\n",
    "    example_html = f.read()\n",
    "    \n",
    "soup = bs4.BeautifulSoup(example_html)\n",
    "print(type(soup))\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating a BeautifulSoup Object from a Remote HTML File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html data-a11y-animated-images=\"system\" data-color-mode=\"auto\" data-dark-theme=\"dark\" data-light-theme=\"light\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <link href=\"https://github.githubassets.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"https://avatars.githubusercontent.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"https://github-cloud.s3.amazonaws.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"https://user-images.githubusercontent.com/\" rel=\"dns-prefetch\"/>\n",
      "  <link crossorigin=\"\" href=\"https://github.githubassets.com\" rel=\"preconnect\"/>\n",
      "  <link href=\"https://avatars.githubusercontent.com\" rel=\"preconnect\"/>\n",
      "  <link crossorigin=\"anonymous\" href=\"https://github.githubassets.com/assets/light-5178aee0ee76.css\" media=\"all\" rel=\"stylesheet\">\n",
      "   <link crossorigin=\"anonymous\" href=\"https://github.githubassets.com/assets/dark-217d4f9c8e70.css\" media=\"all\" rel=\"stylesheet\">\n",
      "    <link crossorigin=\"anonymous\" data-color-theme=\"dark_dimmed\" data-href=\"https://github.githubassets.com/assets/dark_dimmed-0adfa28f0e68.css\" media=\"all\" rel=\"stylesheet\">\n",
      "     <link crossorigin=\"anonymous\" data-color-theme=\"dark_high_contrast\" data-href=\"https://github.githubassets.com/assets/dark_high_contrast-1c8575b36644.css\" media=\"all\" rel=\"stylesheet\">\n",
      "      <link crossorigin=\"anonymous\" data-color-theme=\"dark_colorblind\" data-href=\"https://github.githubassets.com/assets/dark_colorblind-5113d2be20b0.css\" media=\"all\" rel=\"stylesheet\">\n",
      "       <link crossorigin=\"anonymous\" data-color-theme=\"light_colorb\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "\n",
    "r = requests.get('https://github.com/datsoftlyngby/dat4sem2020spring-python')\n",
    "r.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding an Element with the `select()` Method\n",
    "\n",
    "You can retrieve HTML elements from a `BeautifulSoup` object by calling the `select()` method and passing a string of a CSS selector for the element you are looking for. Selectors are like regular expressions: They specify a pattern to look for, in this case, in HTML pages instead of general text strings.\n",
    "\n",
    "Common CSS selector patterns include:\n",
    "\n",
    "  * `soup.select('div')` ... selects all elements named `<div>`\n",
    "  * `soup.select('#lecturer')`  ... selects the element with an id attribute of author\n",
    "  * `soup.select('.notice')` ... selects all elements that use a CSS class attribute named notice\n",
    "  * `soup.select('div span')` ... selects all elements named `<span>` that are within an element named `<div>`\n",
    "  * `soup.select('div > span')` ... selects all elements named `<span>` that are directly within an element named `<div>`, with no other element in between\n",
    "  * `soup.select('input[name]')` ... selects all elements named `<input>` that have a name attribute with any value\n",
    "  * `soup.select('input[type=\"button\"]')` ... selects all elements named `<input>` that have an attribute named type with value button\n",
    "  \n",
    "See more in the documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: return type of select() <class 'bs4.element.ResultSet'>\n",
      "2: length of the returned list 1\n",
      "3: type of elements in the list <class 'bs4.element.Tag'>\n",
      "4: get text from the element \n",
      "Hello World!\n",
      "You are extremely welcome!\n",
      "5: string representation of an element:  <body>\n",
      "<h1>Hello World!</h1>\n",
      "You are extremely welcome!<br/>\n",
      "<br/>\n",
      "The <a href='\\\"https://github.com/datsoftlyngby/dat4sem2019spring-python-materials\\\"'>Lecture Notes</a>.<br/>\n",
      "<div>\n",
      "<p>paragraph 1</p>\n",
      "<p>and paragraph 2: <span id=\"span01\">This is span 1</span><span id=\"span03\">Second span element</span>\n",
      "<span class=\"red_border\">Here is the third span</span>\n",
      "</p>\n",
      "</div>\n",
      "</body>\n",
      "6: the attributes of the element:  {}\n",
      "{'id': 'span01'}\n",
      "{'id': 'span03'}\n",
      "{'class': ['red_border']}\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "\n",
    "with open('./data/example.html') as f:\n",
    "    example_html = f.read()\n",
    "\n",
    "soup = bs4.BeautifulSoup(example_html, 'html.parser')\n",
    "\n",
    "elems = soup.select('body')\n",
    "\n",
    "#print(soup.prettify())\n",
    "print('1: return type of select()',type(elems))\n",
    "print('2: length of the returned list',len(elems))\n",
    "print('3: type of elements in the list',type(elems[0]))\n",
    "print('4: get text from the element',elems[0].getText()[:40])\n",
    "print('5: string representation of an element: ',str(elems[0]))\n",
    "print('6: the attributes of the element: ',elems[0].attrs)\n",
    "elements = soup.select('div > p > span')\n",
    "for element in elements:\n",
    "    print(element.attrs)\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>paragraph 1</p>\n",
      "paragraph 1\n",
      "------------\n",
      "<p>and paragraph 2: <span id=\"span01\">This is span 1</span><span id=\"span03\">Second span element</span>\n",
      "<span class=\"red_border\">Here is the third span</span>\n",
      "</p>\n",
      "and paragraph 2: This is span 1Second span element\n",
      "Here is the third span\n",
      "\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "p_elems = soup.select('p')\n",
    "\n",
    "for el in p_elems:\n",
    "    print(str(el))\n",
    "    print(el.getText())\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting Data from an Element’s Attributes\n",
    "\n",
    "The `get()` method for Tag objects makes it simple to access attribute values from an element. The method is passed a string of an attribute name and returns that attribute’s value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lecturer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'id': 'lecturer'}.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"span01\">This is span 1</span>\n",
      "span01\n",
      "True\n",
      "{'id': 'span01'}\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "with open('./data/example.html') as f:\n",
    "    example_html = f.read()\n",
    "    \n",
    "soup = bs4.BeautifulSoup(example_html, 'html.parser')\n",
    "# soup.find_all?\n",
    "span_elem = soup.select('span')[0]\n",
    "print(str(span_elem))\n",
    "print(span_elem.get('id'))\n",
    "print(span_elem.get('some_nonexistent_addr') == None)\n",
    "print(span_elem.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is the difference between the `select` and the `find`/`find_all` functions?\n",
    "\n",
    "You are not the first ones wondering about this... See:\n",
    "https://stackoverflow.com/questions/38028384/beautifulsoup-is-there-a-difference-between-find-and-select-python-3-x#38033910"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Scraping Events from a Page\n",
    "\n",
    "\n",
    "Ususally, you will use web scraping to collect information, which you cannot gather otherwise. \n",
    "For example, let's imagine we want to do some statistics about:\n",
    "- concerts in Copenhagen, \n",
    "- their start times and \n",
    "- their door prices.\n",
    "\n",
    "Since we cannot find an API or any other open dataset, we decide to scrape the publicly available homepage www.kultunaut.dk, \n",
    "\n",
    "The website lists all possible events in Denmark. \n",
    "Concerts in Copenhagen are for example accessible here: \n",
    "- http://www.kultunaut.dk/perl/arrlist/type-nynaut/UK?showmap=&Area=Kbh.+og+Frederiksberg&periode=&Genre=Musik\n",
    "\n",
    "**OBS** Many web pages are not built to support high traffic or they exlicitely discourage automatic access. Keep this in mind when writing your scraping tool.\n",
    "- from time import sleep\n",
    "- sleep(3) # sleep 3 seconds\n",
    "\n",
    "\n",
    "Considering our example:\n",
    "- we have to first figure out how many events there are at all. \n",
    "- We need this information, as events are given paginated, i.e., twenty events per page.\n",
    "- The link given above only returns the link to the first page with the first twenty events. \n",
    "- Out of the total amount of events we can generate the URLs for the subsequent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kultunaut_2022e = 'https://www.kultunaut.dk/perl/arrlist/type-nynaut/UK?showmap=&Area=Kbh.+og+Frederiksberg&nearmeradius=2000&ArrStartdato=15%2F11+2022&ArrSlutdato=15%2F12+2022&Genre=Musik'\n",
    "kultunaut_url2 = 'https://www.kultunaut.dk/perl/arrlist/type-nynaut/UK?showmap=&Area=Kbh.+og+Frederiksberg&nearmeradius=2000&ArrStartdato=15%2F11+2022&ArrSlutdato=15%2F12+2022&Genre=Musik&Startnr={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of events: 319\n",
      "Div with class arr-genre <div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Morgensang med Christian Bro</strong></h3>\n",
      "</div>\n",
      "\n",
      "\n",
      "[<strong>Morgensang med Christian Bro</strong>, <strong>Korsang i København: Corpo Fairies</strong>, <strong>Johanitterhjælpens støttekoncert</strong>, <strong>Trompetfest med piano og orgel</strong>, <strong>Natkirke: Tonen fra Himlen</strong>, <strong>Cæcilie Norby</strong>, <strong>Ally Venable Band (US)</strong>, <strong>Morgensang - Tema: Kærlighed til alt det skabte</strong>, <strong>Jacob Banks (UK)</strong>, <strong>Rag'n'Bone Man: Life By Misadventure Tour</strong>, <strong>Cæcilie Norby</strong>, <strong>Cmat (ie)</strong>]\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(kultunaut_2022e)\n",
    "\n",
    "r.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "res = soup.select('.result-count > span > strong:nth-child(2)')[0].text\n",
    "no_of_events = res\n",
    "print('no of events: {}'.format(no_of_events))\n",
    "\n",
    "\n",
    "elems = soup.findAll('div',{'class':'arr-genre'})\n",
    "print('Div with class arr-genre',elems[0])\n",
    "print();print()\n",
    "# annother notation\n",
    "elems = soup.select('div[class=arr-genre] > h3 > strong')\n",
    "print(elems)\n",
    "#print(b_el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the browser inspector pane:\n",
    "\n",
    "<img src=\"images/inspect_element.png\" width=\"500\">\n",
    "\n",
    "We can see that the desired element is hiding in a structure like: a b-tag inside a h3-tag inside a td-tag or:\n",
    "- `('td h3 b')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgensang med Christian Bro\n",
      "Korsang i København: Corpo Fairies\n",
      "Johanitterhjælpens støttekoncert\n",
      "Trompetfest med piano og orgel\n",
      "Natkirke: Tonen fra Himlen\n",
      "Cæcilie Norby\n",
      "Ally Venable Band (US)\n",
      "Morgensang - Tema: Kærlighed til alt det skabte\n",
      "Jacob Banks (UK)\n",
      "Rag'n'Bone Man: Life By Misadventure Tour\n",
      "Cæcilie Norby\n",
      "Cmat (ie)\n"
     ]
    }
   ],
   "source": [
    "# use select with css-selectors rather than find_all\n",
    "import bs4\n",
    "import requests\n",
    "html = requests.get(kultunaut_2022e)\n",
    "txt = html.text\n",
    "soup = bs4.BeautifulSoup(txt, 'html.parser')\n",
    "events = soup.select('div[class=arr-genre] > h3 > strong')\n",
    "for e in events:\n",
    "    print(e.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <!-- Initalize title and data source variables -->\n",
      " <head>\n",
      "  <!--\n",
      "\n",
      "------------------------\n",
      "https://analytics.usa.gov/data/\n",
      "https://open.gsa.gov/api/dap/\n",
      "https://analytics.usa.gov/data/live/all-pages-realtime.csv\n",
      "https://analytics.usa.gov/data/live/all-domains-30-days.csv\n",
      "https://www.digitalgov.gov/services/dap/\n",
      "https://www.digitalgov.gov/services/dap/common-questions-about-dap-faq/#part-4\n",
      "https://support.google.com/analytics/answer/2763052?hl=en\n",
      "https://analytics.usa.gov/data/live/second-level-domains.csv\n",
      "https://analytics.usa.gov/data/live/sites.csv\n",
      "https://analytics.usa.gov/data/\n",
      "https://open.gsa.gov/api/dap/\n",
      "https://github.com/GSA/analytics.usa.gov/issues\n",
      "https://github.com/GSA/analytics.usa.gov\n",
      "https://github.com/18F/analytics-reporter\n",
      "https://www.digital.gov/guides/dap/\n",
      "https://cloud.gov/\n"
     ]
    }
   ],
   "source": [
    "# Get all the links in a document\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "gov = requests.get('https://analytics.usa.gov')\n",
    "soup = BeautifulSoup(gov.text, 'lxml')\n",
    "print(soup.prettify()[:100])\n",
    "print('------------------------')\n",
    "for link in soup.find_all('a'):\n",
    "    if not link.get('href').startswith('https'):\n",
    "        continue\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, we can scrape the events per page. Observe, that now, our `base_url` http://www.kultunaut.dk/perl/arrlist/type-nynaut/UK?Startnr={}&showmap=&Area=Kbh.%20og%20Frederiksberg&periode=&Genre=Musik& has a placeholder for the paginated results (`Startnr=`).\n",
    "\n",
    "Consequently, we scrape each page separately, see the function on the next slide: `scrape_events_per_page`. From examining the page's source code, we know that events are all given as table entries with a corresponding header. We iterate over each of the table cells and extract the strings for dates and prices if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/27 [00:00<00:18,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Morgensang med Christian Bro</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Morgensang i Aalholm kirke hver tirsdag morgen. Den bedste måde at begynde dagen på er med en sang. Hver tirsdag morgen i Aalholm Kirke synger vi i vores smukke kirkerum, hvor organisten sidder ved flyglet. Denne tirsdag er det cand. theol.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Tues 15 Nov 2022 8.20 am, <b>Aalholm Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/27 [00:01<00:17,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Whitney (US)</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Whitney vender tilbage til et af deres \"yndlingsspillesteder i hele verden\", når den populære amerikanske folkpop-gruppe indtager Store VEGA i København med ny musik den 16. november.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Wed 16 Nov 2022 8 pm, <b>VEGA</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 3/27 [00:02<00:17,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Funk/Blues/R&amp;B\n",
      "        </span>\n",
      "<h3><strong>Kehlani</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Support: Destin Conrad. KEHLANI I DEN GRÅ HAL 17. NOVEMBER 2022. En af tidens mest betagende R&amp;B-sangerinder, Kehlani, giver koncert i Den Grå Hal til efteråret.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Thur 17 Nov 2022 8 pm, <b>Den Grå Hal, Christiania</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 4/27 [00:02<00:17,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Jazz\n",
      "        </span>\n",
      "<h3><strong>Heine Hansen Trio</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Pianisten Heine Hansen forstår både jazzens amerikanske rødder og lader musikken vokse ind i den skandinaviske tradition vi kender fra bl.a. Jan Johansson og Thomas Clausen. Med sin trio tager han chancer og citerer fra jazzens store sangbog.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Fri 18 Nov 2022 7.30 pm  - 9.30 pm, <b>Kvarterhuset</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 5/27 [00:03<00:17,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Koncert vigdis</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Solstrejf i sneen. Kvindekoret VIGDIS hylder med denne koncert den kolde tid. VIGDIS består af unge kvinder, som alle tidligere har sunget i DR-pigekoret.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sat 19 Nov 2022 5 pm, <b>Solbjerg Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 6/27 [00:04<00:15,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Classical\n",
      "        </span>\n",
      "<h3><strong>Chopins 2. klaverkoncert</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Velkommen til gratis koncert i Ansgarkirken med Kristoffer Hersnack og strygekvartet! Kristoffer Hersnack opfører ved denne koncert F. Chopins 2. klaverkoncert i f-mol med strygekvartet.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sun 20 Nov 2022 4 pm  - 5.30 pm, <b>Ansgarkirken</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 7/27 [00:05<00:14,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Tobe Nwigwe - The moMINTs abroad tour</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Dørene åbner kl. 19.00. https://www.allthingslive.dk/. https://www.facebook.com/allthingslivedenmark/. https://www.tobenwigwe.com/. https://www.vega.dk/.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Mon 21 Nov 2022 8 pm, <b>VEGA</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 8/27 [00:05<00:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Home Concerts - Josephine Philip</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Wed 23 Nov 2022 7.30 pm, <b>La Oficina</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 9/27 [00:06<00:13,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Juniorkor</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Du kan læse mere om vores kor her!\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Thur 24 Nov 2022 3.30 pm, <b>Simon Peters Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 10/27 [00:07<00:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Fredagskoncert</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Musik af Heinrich Schütz i anledning af 350 året for hans død, bl.a. Gejstliche Konzerte. Annemette Pødenphandt, sopran. Rikke Lender, mezzosopran. Gerald Geerink, tenor. Rasmus Kure Thomsen, bas. Kristoffer Thams, orgel og cembalo. Fri entré.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Fri 25 Nov 2022 4.30 pm  - 5.30 pm, <b>Trinitatis Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 11/27 [00:08<00:11,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Queen machine - udsolgt</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Hvis der er udsolgt i forsalg, vil der så være udsolgt i døren.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Fri 25 Nov 2022 9 pm, <b>Amager Bio</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 12/27 [00:08<00:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Soirée karaoke chansons françaises/franske sange</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Venez participer à notre soirée karaoké 100% chansons françaises. Kom og deltag i vores 100 % franske sange karaoke aften. inscription obligatoire/tilmelding nødvendig - info : chansonsfrancaisesdk@gmail.com coronapas nødvendig.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sat 26 Nov 2022 6.30 pm  - 10.00 pm, <b>Metronomen</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 13/27 [00:09<00:10,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Adventsmusik</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Sankt Markus Kirkes kor opfører en halvt times musik til adventstiden under ledelse af organisten David Bendix Nielsen.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sun 27 Nov 2022 10 am, <b>Sankt Markus Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 14/27 [00:10<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Set it off</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Koncerten er flyttet til d. 28. november 2022. Allerde købte billetter gælder til den nye dato. Refunderingsfrist: 8. april 2022. __________________________________________.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Mon 28 Nov 2022 8 pm, <b>Pumpehuset</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 15/27 [00:11<00:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Nothing,nowhere</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Dørene åbner kl. 19.00. Se mere på. https://www.facebook.com/allthingslivedenmark. http://www.allthingslive.dk/.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Wed 30 Nov 2022 8 pm, <b>Pumpehuset</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 16/27 [00:11<00:08,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Gospel/Choir/Sing-along\n",
      "        </span>\n",
      "<h3><strong>Copenhagen Gospel Choir</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Syng med! Næste sæsonstart: Torsdag, d. 1. september 2022. Vi øver hver torsdag, fordelt på 2 hold: · Hold 1: Kl. 17:00 - 19:00 · Hold 2: Kl. 19:30 - 21:30 Vælg det hold der passer dig bedst. V Sted: Timotheuskirken, Christen Bergs Allé 5, 2500 Valby.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Thur 1 Dec 2022 5 pm, <b>Timotheuskirken</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 17/27 [00:12<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Hip-Hop/Reggae\n",
      "        </span>\n",
      "<h3><strong>Masego // Studying Abroad Tour - Ekstra Koncert</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Se mere.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Fri 2 Dec 2022 8 pm, <b>Amager Bio</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 18/27 [00:13<00:06,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Classical\n",
      "        </span>\n",
      "<h3><strong>Klassisk koncert med Kian Kristensen Rashid</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>En klassisk koncert som har til måls at give et indblik ind i de store og de små følelser der ligger skjult mellem musikkens linjer. Med et program præget af Mozart, Schumann og Prokofiev.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sun 4 Dec 2022 Kl 18:30 - 7.40 pm, <b>Metronomen</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 19/27 [00:14<00:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Madison Cunningham (US)</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Læs mere.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sun 4 Dec 2022 8 pm, <b>Ideal Bar</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 20/27 [00:14<00:05,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Gospel/Choir/Sing-along\n",
      "        </span>\n",
      "<h3><strong>Korsang i København: Corpo Fairies</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Et utraditionelt kor, vi synger sange fra Bulgarien, Georgien, Romasange og gospel. Plus improvisation, lydunivers, tonelandskaber, meditation og lydhealing.\n",
      "\n",
      "  Organizer VoiceColour.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Tues 6 Dec 2022 6.00 pm  - 8.30 pm, <b>Christianshavns Beboerhus</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 21/27 [00:15<00:04,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Nicklas Sahl (DK)</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Læs mere.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Wed 7 Dec 2022 8 pm, <b>VEGA</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 22/27 [00:16<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Julefryd, stille fred</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>På omtrent dette tidspunkt hvert år i december er skuldrene godt på vej op omkring ørerne, jagten på den perfekte jul er gået ind og de fleste har glemt hvad det nu egentlig var det der med jul drejede sig om.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Thur 8 Dec 2022 9 pm, <b>Lindevang Kirke</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 23/27 [00:17<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Moonjam / Julekoncert M. Special Guest</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Hvis der er udsolgt i forsalg, vil der så være udsolgt i døren.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Fri 9 Dec 2022 9 pm, <b>Amager Bio</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 24/27 [00:17<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Paul Potts</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Paul Potts' vender tilbage til Danmark, og med sig har han Gry Johansen på dette års turne.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sat 10 Dec 2022 8 pm, <b>Docken Nordhavn</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 25/27 [00:18<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Rock/Pop\n",
      "        </span>\n",
      "<h3><strong>Mouritz/Hørslev Projektet (DK)</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Læs mere.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Sun 11 Dec 2022 8 pm, <b>VEGA</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 26/27 [00:19<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Hip-Hop/Reggae\n",
      "        </span>\n",
      "<h3><strong>Little Simz</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>OBS: Koncerten med Little Simz d. 15 januar 2022 i Amager Bio udskydes til d. 14 december 2022. Billetkøbere skal blot beholde den nuværende billet og møde op til koncerten d. 14 december 2022.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Wed 14 Dec 2022 8 pm, <b>Amager Bio</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:19<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"arr-info\">\n",
      "<div class=\"arr-genre\">\n",
      "<span class=\"genre_cat notranslate\">\n",
      "          Music\n",
      "          \n",
      "        </span>\n",
      "<h3><strong>Julekoncert med Nathanaelskoret</strong></h3>\n",
      "</div>\n",
      "<div class=\"arr-description\"><span>Nathanaelskorets julekoncert.\n",
      "\n",
      "</span>\n",
      "</div>\n",
      "<div class=\"kult-month-day\">\n",
      "<time>Thur 15 Dec 2022 7.30 pm, <b>Nathanaels Kirke  og sognegård</b></time>\n",
      "<div class=\"arrow_right\"><img alt=\"arrow right\" src=\"https://www.kultunaut.dk/images/nynaut22/np-arrow-right.png\"/></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "    \n",
    "def scrape_events_per_page(url):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        A list of tuples of strings holding title, place, date, and price\n",
    "        for concerts in Copenhagen scraped from Kulturnaut.dk\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    event_cells = soup.find_all('div', {'class' : 'arr-info'})\n",
    "    #print('size',len(event_cells))\n",
    "    print(event_cells[0])\n",
    "    scraped_events_per_page = []\n",
    "    \n",
    "    for event_cell in event_cells:\n",
    "        try:\n",
    "            title = event_cell.select('h3 > strong')[0].text\n",
    "            rest = event_cell.find('time').text.split(',')\n",
    "            try:\n",
    "                place = rest[1]\n",
    "            except:\n",
    "                place = ''\n",
    "            try:\n",
    "                date = rest[0]\n",
    "            except:\n",
    "                date = ''\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        scraped_events_per_page.append((title, place, date))\n",
    "        \n",
    "    return scraped_events_per_page\n",
    "\n",
    "\n",
    "scraped_events = []\n",
    "indexes = list(range(1, int(no_of_events), 12))\n",
    "indexes[0] = 0\n",
    "\n",
    "\n",
    "for idx in tqdm(indexes):\n",
    "    scrape_url = kultunaut_url2.format(idx)\n",
    "    #print(scrape_url)\n",
    "    scraped_events += scrape_events_per_page(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scraped_events[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to Extract Dates and Prices from Strings.\n",
    "\n",
    "Remember, the raw data, which we extracted from the web pages is all of type `str`. To do statistics about possible correlation of start times and entry fees, we need to convert the corresponding tuple fields into datetimes and integers respectively.\n",
    "\n",
    "\n",
    "Since dates given on the web do not necessarily conform to standardized time formats, we can apply the `dateparser` (https://pypi.python.org/pypi/dateparser) module, which tries to parse arbitrary strings into datetimes.\n",
    "\n",
    "You can read more about the module and its capabilities https://dateparser.readthedocs.io/en/latest/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#pip install dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/319 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n",
      "100%|██████████| 319/319 [00:04<00:00, 65.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2022, 11, 15, 8, 20), datetime.datetime(2022, 11, 15, 18, 0), datetime.datetime(2022, 11, 15, 19, 0), datetime.datetime(2022, 11, 15, 19, 30), datetime.datetime(2022, 11, 15, 19, 30), datetime.datetime(2022, 11, 15, 20, 0), datetime.datetime(2022, 11, 15, 20, 0), datetime.datetime(2022, 11, 16, 8, 20), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 16, 20, 0), datetime.datetime(2022, 11, 18, 21, 0), datetime.datetime(2022, 11, 18, 14, 0), datetime.datetime(2022, 11, 18, 15, 0), datetime.datetime(2022, 11, 18, 15, 30), datetime.datetime(2022, 11, 18, 18, 0), datetime.datetime(2022, 11, 18, 18, 0), datetime.datetime(2022, 11, 18, 19, 30), datetime.datetime(2022, 11, 18, 19, 30), datetime.datetime(2022, 11, 18, 19, 30), datetime.datetime(2022, 11, 18, 19, 30), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 18, 20, 0), datetime.datetime(2022, 11, 19, 10, 0), datetime.datetime(2022, 11, 19, 14, 0), datetime.datetime(2022, 11, 19, 14, 30), datetime.datetime(2022, 11, 19, 17, 0), datetime.datetime(2022, 11, 19, 19, 30), datetime.datetime(2022, 11, 19, 20, 0), datetime.datetime(2022, 11, 19, 20, 0), datetime.datetime(2022, 11, 19, 20, 0), datetime.datetime(2022, 11, 19, 22, 0), datetime.datetime(2022, 11, 20, 11, 0), datetime.datetime(2022, 11, 20, 14, 0), datetime.datetime(2022, 11, 20, 14, 30), datetime.datetime(2022, 11, 20, 16, 0), datetime.datetime(2022, 11, 20, 16, 0), datetime.datetime(2022, 11, 20, 16, 0), datetime.datetime(2022, 11, 20, 16, 0), datetime.datetime(2022, 11, 20, 17, 0), datetime.datetime(2022, 11, 20, 20, 0), datetime.datetime(2022, 11, 20, 20, 0), datetime.datetime(2022, 11, 20, 20, 0), datetime.datetime(2022, 11, 20, 20, 0), datetime.datetime(2022, 11, 21, 19, 30), datetime.datetime(2022, 11, 21, 16, 0), datetime.datetime(2022, 11, 21, 19, 30), datetime.datetime(2022, 11, 21, 19, 30), datetime.datetime(2022, 11, 21, 20, 0), datetime.datetime(2022, 11, 21, 20, 0), datetime.datetime(2022, 11, 21, 20, 0), datetime.datetime(2022, 11, 22, 8, 20), datetime.datetime(2022, 11, 22, 19, 0), datetime.datetime(2022, 11, 22, 19, 30), datetime.datetime(2022, 11, 22, 20, 0), datetime.datetime(2022, 11, 22, 20, 0), datetime.datetime(2022, 11, 22, 20, 0), datetime.datetime(2022, 11, 23, 8, 20), datetime.datetime(2022, 11, 23, 18, 0), datetime.datetime(2022, 11, 23, 19, 0), datetime.datetime(2022, 11, 23, 19, 30), datetime.datetime(2022, 11, 23, 19, 30), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 23, 20, 0), datetime.datetime(2022, 11, 25, 15, 30), datetime.datetime(2022, 11, 25, 16, 30), datetime.datetime(2022, 11, 25, 16, 0), datetime.datetime(2022, 11, 25, 17, 0), datetime.datetime(2022, 11, 25, 18, 0), datetime.datetime(2022, 11, 25, 19, 0), datetime.datetime(2022, 11, 25, 19, 0), datetime.datetime(2022, 11, 25, 19, 30), datetime.datetime(2022, 11, 25, 19, 30), datetime.datetime(2022, 11, 25, 20, 0), datetime.datetime(2022, 11, 25, 20, 0), datetime.datetime(2022, 11, 25, 20, 0), datetime.datetime(2022, 11, 25, 20, 0), datetime.datetime(2022, 11, 25, 21, 0), datetime.datetime(2022, 11, 25, 21, 0), datetime.datetime(2022, 11, 26, 14, 0), datetime.datetime(2022, 11, 26, 14, 0), datetime.datetime(2022, 11, 26, 14, 30), datetime.datetime(2022, 11, 26, 15, 0), datetime.datetime(2022, 11, 26, 15, 0), datetime.datetime(2022, 11, 26, 16, 0), datetime.datetime(2022, 11, 26, 16, 0), datetime.datetime(2022, 11, 26, 16, 0), datetime.datetime(2022, 11, 26, 18, 0), datetime.datetime(2022, 11, 26, 18, 30), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 20, 0), datetime.datetime(2022, 11, 26, 21, 0), datetime.datetime(2022, 11, 26, 21, 0), datetime.datetime(2022, 11, 26, 21, 0), datetime.datetime(2022, 11, 27, 14, 0), datetime.datetime(2022, 11, 27, 10, 0), datetime.datetime(2022, 11, 27, 16, 0), datetime.datetime(2022, 11, 27, 16, 0), datetime.datetime(2022, 11, 27, 16, 0), datetime.datetime(2022, 11, 27, 16, 0), datetime.datetime(2022, 11, 27, 20, 0), datetime.datetime(2022, 11, 27, 20, 0), datetime.datetime(2022, 11, 27, 20, 0), datetime.datetime(2022, 11, 28, 16, 0), datetime.datetime(2022, 11, 28, 19, 0), datetime.datetime(2022, 11, 28, 19, 30), datetime.datetime(2022, 11, 28, 19, 30), datetime.datetime(2022, 11, 28, 20, 0), datetime.datetime(2022, 11, 28, 20, 0), datetime.datetime(2022, 11, 28, 20, 0), datetime.datetime(2022, 11, 28, 20, 0), datetime.datetime(2022, 11, 29, 8, 20), datetime.datetime(2022, 11, 29, 14, 0), datetime.datetime(2022, 11, 29, 18, 0), datetime.datetime(2022, 11, 29, 19, 30), datetime.datetime(2022, 11, 29, 20, 0), datetime.datetime(2022, 11, 29, 20, 0), datetime.datetime(2022, 11, 29, 20, 0), datetime.datetime(2022, 11, 30, 8, 20), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 11, 30, 20, 0), datetime.datetime(2022, 12, 2, 15, 0), datetime.datetime(2022, 12, 2, 15, 30), datetime.datetime(2022, 12, 2, 17, 0), datetime.datetime(2022, 12, 2, 17, 0), datetime.datetime(2022, 12, 2, 20, 0), datetime.datetime(2022, 12, 2, 20, 0), datetime.datetime(2022, 12, 3, 15, 0), datetime.datetime(2022, 12, 3, 21, 0), datetime.datetime(2022, 12, 3, 11, 0), datetime.datetime(2022, 12, 3, 11, 0), datetime.datetime(2022, 12, 3, 16, 0), datetime.datetime(2022, 12, 3, 16, 0), datetime.datetime(2022, 12, 3, 18, 0), datetime.datetime(2022, 12, 3, 20, 0), datetime.datetime(2022, 12, 4, 16, 0), datetime.datetime(2022, 12, 4, 16, 0), datetime.datetime(2022, 12, 4, 13, 0), datetime.datetime(2022, 12, 4, 13, 0), datetime.datetime(2022, 12, 4, 15, 0), datetime.datetime(2022, 12, 4, 16, 0), datetime.datetime(2022, 12, 4, 16, 0), datetime.datetime(2022, 12, 4, 17, 0), datetime.datetime(2022, 12, 4, 17, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 4, 20, 0), datetime.datetime(2022, 12, 5, 16, 0), datetime.datetime(2022, 12, 5, 17, 0), datetime.datetime(2022, 12, 5, 19, 30), datetime.datetime(2022, 12, 5, 19, 30), datetime.datetime(2022, 12, 5, 19, 30), datetime.datetime(2022, 12, 5, 20, 0), datetime.datetime(2022, 12, 5, 20, 0), datetime.datetime(2022, 12, 6, 14, 30), datetime.datetime(2022, 12, 6, 17, 0), datetime.datetime(2022, 12, 6, 17, 0), datetime.datetime(2022, 12, 6, 18, 0), datetime.datetime(2022, 12, 6, 19, 0), datetime.datetime(2022, 12, 6, 19, 30), datetime.datetime(2022, 12, 6, 20, 0), datetime.datetime(2022, 12, 6, 20, 0), datetime.datetime(2022, 12, 7, 10, 0), datetime.datetime(2022, 12, 7, 15, 0), datetime.datetime(2022, 12, 7, 19, 0), datetime.datetime(2022, 12, 7, 20, 0), datetime.datetime(2022, 12, 7, 20, 0), datetime.datetime(2022, 12, 7, 20, 0), datetime.datetime(2022, 12, 7, 20, 0), datetime.datetime(2022, 12, 9, 14, 0), datetime.datetime(2022, 12, 9, 16, 30), datetime.datetime(2022, 12, 9, 17, 0), datetime.datetime(2022, 12, 9, 17, 0), datetime.datetime(2022, 12, 9, 19, 30), datetime.datetime(2022, 12, 9, 19, 30), datetime.datetime(2022, 12, 9, 19, 30), datetime.datetime(2022, 12, 9, 19, 30), datetime.datetime(2022, 12, 9, 20, 0), datetime.datetime(2022, 12, 9, 20, 0), datetime.datetime(2022, 12, 9, 20, 0), datetime.datetime(2022, 12, 9, 21, 0), datetime.datetime(2022, 12, 10, 21, 0), datetime.datetime(2022, 12, 10, 13, 0), datetime.datetime(2022, 12, 10, 15, 0), datetime.datetime(2022, 12, 10, 16, 0), datetime.datetime(2022, 12, 10, 16, 0), datetime.datetime(2022, 12, 10, 18, 0), datetime.datetime(2022, 12, 10, 18, 30), datetime.datetime(2022, 12, 10, 19, 30), datetime.datetime(2022, 12, 10, 19, 30), datetime.datetime(2022, 12, 10, 20, 0), datetime.datetime(2022, 12, 10, 20, 0), datetime.datetime(2022, 12, 10, 20, 0), datetime.datetime(2022, 12, 10, 20, 0), datetime.datetime(2022, 12, 10, 21, 0), datetime.datetime(2022, 12, 11, 15, 0), datetime.datetime(2022, 12, 11, 15, 0), datetime.datetime(2022, 12, 11, 16, 0), datetime.datetime(2022, 12, 11, 16, 0), datetime.datetime(2022, 12, 11, 16, 0), datetime.datetime(2022, 12, 11, 16, 0), datetime.datetime(2022, 12, 11, 19, 0), datetime.datetime(2022, 12, 11, 19, 30), datetime.datetime(2022, 12, 11, 20, 0), datetime.datetime(2022, 12, 11, 20, 0), datetime.datetime(2022, 12, 12, 16, 0), datetime.datetime(2022, 12, 13, 17, 30), datetime.datetime(2022, 12, 13, 19, 30), datetime.datetime(2022, 12, 13, 19, 30), datetime.datetime(2022, 12, 13, 19, 30), datetime.datetime(2022, 12, 13, 20, 0), datetime.datetime(2022, 12, 13, 20, 0), datetime.datetime(2022, 12, 14, 16, 0), datetime.datetime(2022, 12, 14, 17, 0), datetime.datetime(2022, 12, 14, 19, 30), datetime.datetime(2022, 12, 14, 19, 30), datetime.datetime(2022, 12, 14, 20, 0), datetime.datetime(2022, 12, 14, 20, 0), datetime.datetime(2022, 12, 14, 20, 0), datetime.datetime(2022, 12, 14, 21, 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from dateparser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_dates_and_prices(scraped_events):\n",
    "    \"\"\"\n",
    "    NO LONGER WORKS WELL WITH KULTUNAUT website after they changes layout and hid the prices behind a js function.\n",
    "    Cleanup the data. Get price as integer and date as date.\n",
    "    \n",
    "    returns:\n",
    "        A two-element tuple with a datetime representing the start \n",
    "        time of an event and an integer representing the price in Dkk.\n",
    "    \"\"\"\n",
    "\n",
    "    price_regexp = r\"(?P<price>\\d+)\" #initial ? is a lookbehind. r() r is for raw text, P<some pattern> is to give a pattern name to refer to. \\d is numeric digit, + is for 1 or more.\n",
    "\n",
    "    data_points = []\n",
    "    three_at_night = datetime.now().replace(hour=3, minute=0, second=0, microsecond=0).time()\n",
    "    for event_data in tqdm(scraped_events):\n",
    "        title_str, place_str, date_str, price_str = event_data\n",
    "        \n",
    "        if 'Free admission' in price_str:\n",
    "            price = 0\n",
    "        else:\n",
    "            m = re.search(price_regexp, price_str) # m is the Match object returned from re.search (might be None)\n",
    "            try:\n",
    "                price = int(m.group('price')) # if price can be converted to int then we do it else return 0.\n",
    "            except:\n",
    "                price = 0\n",
    "\n",
    "        date_str = date_str.strip().strip('.')\n",
    "        if '&' in date_str:\n",
    "            date_str = date_str.split('&')[0]\n",
    "        if '-' in date_str:\n",
    "            date_str = date_str.split('-')[0]\n",
    "        if '.' in date_str:\n",
    "            date_str = date_str.replace('.', ':')\n",
    "        \n",
    "        date = parse(date_str)\n",
    "        if date and date.time() > three_at_night:\n",
    "            data_points.append((date, price))\n",
    "            \n",
    "    return data_points\n",
    "\n",
    "def get_dates(scraped_events):\n",
    "    \"\"\"\n",
    "    Cleanup the data. Get date as date.\n",
    "    \n",
    "    returns:\n",
    "        A datetime representing the start \n",
    "        time of an event.\n",
    "    \"\"\"\n",
    "    three_at_night = datetime.now().replace(hour=3, minute=0, second=0, microsecond=0).time()\n",
    "    dates = []\n",
    "    for event_data in tqdm(scraped_events):\n",
    "        title_str, place_str, date_str = event_data\n",
    "        \n",
    "        date_str = date_str.strip().strip('.')\n",
    "        if '&' in date_str:\n",
    "            date_str = date_str.split('&')[0]\n",
    "        if '-' in date_str:\n",
    "            date_str = date_str.split('-')[0]\n",
    "        if '.' in date_str:\n",
    "            date_str = date_str.replace('.', ':')\n",
    "        \n",
    "        date = parse(date_str)\n",
    "        if date and date.time() > three_at_night:\n",
    "            dates.append(date)\n",
    "    return dates\n",
    "\n",
    "dates = get_dates(scraped_events)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dates[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping Images from a Page\n",
    "\n",
    "In the following code you will use Beautiful Soup to extract all links to images, which are in `img` tags on a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsoEDUxaYMfyrf9YpsbZI84gSY5xvvjQ-dOFy9pqD2nFir8-D4Jmed-GAFXQ&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQeyctG9tUDC5VuiPT0fmcNfpka1vbjkyaz4b0EfwEFJbM6thWGtBZA4IbpOR8&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSJWWVrFCSqO1s9SLTpANuqMXnJYUYvCdCT29e3J7dNsNU8CIvSnVl9eP71QVQ&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSbX6jFwptGkZ0GFTx0s5HSuqx-6ichbd9yhFdLCIOTWi7ng7vKBfD_Yuch7zI&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSp22_qmF6ljKHcBt-d-HIZ-jW8WNcIKuhxWZIawRFQ3xW-P9T4v_x_CrDtjQ&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTnUim_kuO8HLKOi_3p7VdlO3Tm-5znWb1oIiq13oBqxsA9yn-UnJLdZGZnNnc&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSxfMwig0ZYdlJpPsFjw8HefcjgMTeTlB5hWDXSlSQTsnQXYnPkheh3mqo8Ayg&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQc8M4CKrXBdTY3U4ek9Z1mITF82r8qoN6xiLGPzaQvT7r_Eg0BBMN1GuP-CA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRKyCmsZbx_imIkVIyxeU4D1RXHR6SBOEJWFCK3Lw1m6yyxBeKLx7P_sieWcA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQS-E-b-s9SqJQqkmNyyjFIyovLio_JHQxvRVrSwjZQGGxzFDLbHilciPNLFA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR4myw7zwMK7cA0erzJDqsw5G2k7mKlCmZm58SgYbXdB5kP3KepCQK3UPhnuA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ9SBH6JsMx7L-dOETZEb2I2VWHlgNWAAYDPU61QSvs9jCjSkNUZiiMN_pG9g&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRUDRQMPt6O6vw6R7jEVSr13EtjF-jlzGTsoH0eTIcnAxynpBZPFyBsXvADgQ&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTXLWWEmiPzhc9kx-eap5BspfL8bMv-IJgfMQM0DNd4Co13jo8wII1cEcicNg&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTF1_2UxVJrQC4QVcfai4uxDDrMh8kr5AIz5oW4hi8M7ODHW_O-zW2QQFJ9Yg&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRdt-2Vv4v0DjQQNsPfSInyZWOLKJpfDwnYFnXUB-bIPm1NeC-nJJyawG8mJw&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQQ9xAJQYxaFNfGzTXiApu4udilfwWtoYdyjJUczAQJTC-imTz8myqwYczByJs&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSICpSwMbAk0oor-IoPVTsGMuQXSc-kkaCZVT45pjZMm9r4eFirPzZj2xDz418&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRle3ihjsohg0DODcaPGrKVmtsNCS7oYMlkbQ1kJ5p6D7MTRPZdNp3dLFKlz70&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS3fP00A_zbIPerPEY6d9-s_yGZOMDC-y81kIM52QJt8PVPtd6WEwpFv0pTTA&s']\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "\n",
    "def collect_img_links(url):\n",
    "    \"\"\"based on a url returns a list of image links contained in the requested page\"\"\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #print(soup.select('img'))\n",
    "    return [img.get('src') for img in soup.select('img') \n",
    "            if img.get('src') and img.get('src').startswith('http')]\n",
    "\n",
    "\n",
    "def download_imgs(links, out_folder=\"./data/test/\"):\n",
    "    \"\"\"download all images from a list of image links. \n",
    "    Requires a folder named: test to be there\"\"\"\n",
    "    img_no = 0\n",
    "    for l in links:\n",
    "        img_no += 1\n",
    "        r = requests.get(l, stream=True)\n",
    "        with open(out_folder+'img'+str(img_no)+'.jpg', 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)     \n",
    "        \n",
    "links = collect_img_links('https://www.google.dk/search?site=&tbm=isch&source=hp&biw=1163&bih=812&q=minions&oq=minions')\n",
    "print(links)\n",
    "download_imgs(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Exercise: Writing a Simple Web Crawler\n",
    "\n",
    "1. Write a simple web scraper that can capture all images in a document (like: https://www.cphbusiness.dk/). \n",
    "2. Write to a .md file in a format so all images are shown when markdown is pasted and executed in a cell\n",
    "3. Extend the web scraper to find all links (`<a>` elements) in the document.\n",
    "4. If you have time, let the crawler find all links in the linked documents as well (so we get one more level of the hypertext graph). Use threads if helpfull.\n",
    "\n",
    "\n",
    "In case a page returns a status code, which is not `200` we just disregard this page. See https://en.wikipedia.org/wiki/List_of_HTTP_status_codes for more detailes on the various HTTP status codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_links(from_url, for_depth, all_links={}):\n",
    "    # TODO: Implement code for websraper\n",
    "    # return dict(key=url, value=list of outgoing urls)\n",
    "    pass\n",
    "\n",
    "\n",
    "start_url = 'https://www.version2.dk/artikel/google-deepmind-vi-oeger-sikkerheden-mod-misbrug-sundhedsdata-1074452'\n",
    "\n",
    "link_dict = scrape_links(from_url=start_url, for_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scrapy\n",
    "The web crawler that you wrote above is perhaps not the most performant. If you are interested in more web scraping and application of crawlers have a look at the `scrapy` module (https://scrapy.org)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
